{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from setup import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = config.cast('feature')\n",
    "feature_ind_config = feature_config.cast('ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取某一类的特征列名\n",
    "def get_feature_column_name_list(df: pd.DataFrame, prefix: str) -> list:\n",
    "    columns = list(df.columns)\n",
    "    return [col for col in columns if col.startswith(prefix)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查特征列里有没有缺失值\n",
    "def get_name_list_of_feature_with_missing_value(df: pd.DataFrame, feature: list, placeholder) -> list:\n",
    "    col_has_missing_value = []\n",
    "    for col in feature:\n",
    "        value_counts = df[col].value_counts()\n",
    "        value_counts_index = list(value_counts.index)\n",
    "        if placeholder in value_counts_index:\n",
    "            col_has_missing_value.append(col)\n",
    "    return col_has_missing_value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train_path = config.data.path('train.csv')\n",
    "data_set_train_ind_path = config.data.path('train_ind.csv')\n",
    "data_set_train_ind_uniquified_path = config.data.path('train_ind_uniquified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train = pd.read_csv(data_set_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_data_set_train_ind_columns = get_feature_column_name_list(data_set_train, prefix='ps_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取属性 ps_ind 相关列\n",
    "_data_set_train_ind = data_set_train[['id', 'target']+_data_set_train_ind_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在缺失值的列: ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat']\n"
     ]
    }
   ],
   "source": [
    "feature_with_missing_value = get_name_list_of_feature_with_missing_value(\n",
    "    _data_set_train_ind, \n",
    "    feature=_data_set_train_ind_columns,\n",
    "    placeholder=-1\n",
    ")\n",
    "print('存在缺失值的列: ' + str(feature_with_missing_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_feature_ps_ind(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # 存在缺失值的都是 category, 直接 one-hot编码\n",
    "    df_columns = list(df.columns)\n",
    "    _df = pd.get_dummies(\n",
    "        data=df, \n",
    "        columns=[col for col in df_columns if '_cat' in col]\n",
    "    )\n",
    "    \n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train_ind = fix_feature_ps_ind(_data_set_train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train_ind_columns = list(data_set_train_ind.columns)\n",
    "feature_ind_length = len(get_feature_column_name_list(df=data_set_train_ind, prefix='ps_ind'))\n",
    "feature_ind_config.parameter.put(tag='length', value=feature_ind_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "data_set_train_ind.to_csv(path_or_buf=data_set_train_ind_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每个列加上一个基数\n",
    "def uniquify(df: pd.DataFrame, columns: list, offset: int=0, neat: bool = True) -> (pd.DataFrame, int):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        # 如果要精简, 每列先减去其最小值\n",
    "        \n",
    "        col_min = df[col].min()\n",
    "        col_max = df[col].max()\n",
    "        \n",
    "        col_value_range_length = col_max - col_min + 1\n",
    "        \n",
    "        # 每列减去最小值\n",
    "        if col_min != 0 and neat:\n",
    "            df[col] = df[col] - col_min\n",
    "            \n",
    "        col_unique_value = sorted(pd.unique(df[col]))\n",
    "        col_unique_value_number = \\\n",
    "            len(col_unique_value) if col_value_range_length <= len(col_unique_value) else col_value_range_length\n",
    "        \n",
    "        print(col, col_max, col_min, col_unique_value_number, col_unique_value)\n",
    "        \n",
    "        df[col] = df[col] + offset\n",
    "        offset = offset + col_unique_value_number\n",
    "    \n",
    "    return df, offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_01 7 0 8 [0, 1, 2, 3, 4, 5, 6, 7]\nps_ind_03 11 0 12 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\nps_ind_06_bin 1 0 2 [0, 1]\nps_ind_07_bin 1 0 2 [0, 1]\nps_ind_08_bin 1 0 2 [0, 1]\nps_ind_09_bin 1 0 2 [0, 1]\nps_ind_10_bin 1 0 2 [0, 1]\nps_ind_11_bin 1 0 2 [0, 1]\nps_ind_12_bin 1 0 2 [0, 1]\nps_ind_13_bin 1 0 2 [0, 1]\nps_ind_14 4 0 5 [0, 1, 2, 3, 4]\nps_ind_15 13 0 14 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\nps_ind_16_bin 1 0 2 [0, 1]\nps_ind_17_bin 1 0 2 [0, 1]\nps_ind_18_bin 1 0 2 [0, 1]\nps_ind_02_cat_-1 1 0 2 [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_02_cat_1 1 0 2 [0, 1]\nps_ind_02_cat_2 1 0 2 [0, 1]\nps_ind_02_cat_3 1 0 2 [0, 1]\nps_ind_02_cat_4 1 0 2 [0, 1]\nps_ind_04_cat_-1 1 0 2 [0, 1]\nps_ind_04_cat_0 1 0 2 [0, 1]\nps_ind_04_cat_1 1 0 2 [0, 1]\nps_ind_05_cat_-1 1 0 2 [0, 1]\nps_ind_05_cat_0 1 0 2 [0, 1]\nps_ind_05_cat_1 1 0 2 [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_05_cat_2 1 0 2 [0, 1]\nps_ind_05_cat_3 1 0 2 [0, 1]\nps_ind_05_cat_4 1 0 2 [0, 1]\nps_ind_05_cat_5 1 0 2 [0, 1]\nps_ind_05_cat_6 1 0 2 [0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_ind_embedding_offset = 0\n",
    "    \n",
    "data_set_train_ind_uniquified, limit = \\\n",
    "    uniquify(\n",
    "        data_set_train_ind, \n",
    "        get_feature_column_name_list(df=data_set_train_ind, prefix='ps_ind'), \n",
    "        offset=feature_ind_embedding_offset\n",
    "    )\n",
    "\n",
    "feature_ind_embedding_limit = math.ceil(limit/100)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# 将每一列的特征社转为embedding的idx\n",
    "\n",
    "print(feature_ind_embedding_limit)\n",
    "\n",
    "feature_ind_config.parameter.put('embedding.offset', feature_ind_embedding_offset)\n",
    "feature_ind_config.parameter.put('embedding.limit', feature_ind_embedding_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_train_ind_uniquified.to_csv(path_or_buf=data_set_train_ind_uniquified_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.963552\n1    0.036448\nName: target, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train_ind_uniquified['target'].value_counts() / data_set_train_ind_uniquified['target'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set_test_path = config.data.path('test.csv')\n",
    "data_set_test_ind_path = config.data.path('test_ind.csv')\n",
    "data_set_test_ind_uniquified_path = config.data.path('test_ind_uniquified.csv')\n",
    "data_set_test = pd.read_csv(data_set_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_01 7 0 8 [0, 1, 2, 3, 4, 5, 6, 7]\nps_ind_03 11 0 12 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\nps_ind_06_bin 1 0 2 [0, 1]\nps_ind_07_bin 1 0 2 [0, 1]\nps_ind_08_bin 1 0 2 [0, 1]\nps_ind_09_bin 1 0 2 [0, 1]\nps_ind_10_bin 1 0 2 [0, 1]\nps_ind_11_bin 1 0 2 [0, 1]\nps_ind_12_bin 1 0 2 [0, 1]\nps_ind_13_bin 1 0 2 [0, 1]\nps_ind_14 4 0 5 [0, 1, 2, 3, 4]\nps_ind_15 13 0 14 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\nps_ind_16_bin 1 0 2 [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_17_bin 1 0 2 [0, 1]\nps_ind_18_bin 1 0 2 [0, 1]\nps_ind_02_cat_-1 1 0 2 [0, 1]\nps_ind_02_cat_1 1 0 2 [0, 1]\nps_ind_02_cat_2 1 0 2 [0, 1]\nps_ind_02_cat_3 1 0 2 [0, 1]\nps_ind_02_cat_4 1 0 2 [0, 1]\nps_ind_04_cat_-1 1 0 2 [0, 1]\nps_ind_04_cat_0 1 0 2 [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_04_cat_1 1 0 2 [0, 1]\nps_ind_05_cat_-1 1 0 2 [0, 1]\nps_ind_05_cat_0 1 0 2 [0, 1]\nps_ind_05_cat_1 1 0 2 [0, 1]\nps_ind_05_cat_2 1 0 2 [0, 1]\nps_ind_05_cat_3 1 0 2 [0, 1]\nps_ind_05_cat_4 1 0 2 [0, 1]\nps_ind_05_cat_5 1 0 2 [0, 1]\nps_ind_05_cat_6 1 0 2 [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 处理测试数据\n",
    "\n",
    "_data_set_test_ind_columns = get_feature_column_name_list(data_set_test, prefix='ps_ind')\n",
    "_data_set_test_ind = data_set_test[['id']+_data_set_test_ind_columns]\n",
    "data_set_test_ind = fix_feature_ps_ind(_data_set_test_ind)\n",
    "\n",
    "data_set_test_ind.to_csv(path_or_buf=data_set_test_ind_path, index=False)\n",
    "\n",
    "data_set_test_ind_columns_ind_only = get_feature_column_name_list(data_set_test_ind, prefix='ps_ind')\n",
    "\n",
    "feature_ind_embedding_offset = 0\n",
    "    \n",
    "data_set_test_ind_uniquified, limit = \\\n",
    "    uniquify(data_set_test_ind, data_set_test_ind_columns_ind_only, offset=feature_ind_embedding_offset)\n",
    "\n",
    "feature_ind_embedding_limit = math.ceil(limit/100)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_set_test_ind_uniquified.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_test_ind_uniquified.to_csv(path_or_buf=data_set_test_ind_uniquified_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
